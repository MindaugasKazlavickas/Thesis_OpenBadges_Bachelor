\phantomsection
\section*{CONCLUSIONS}
\addcontentsline{toc}{section}{CONCLUSIONS}
\begin{enumerate}
    \item \textbf{Theoretical Foundations} The literature analysis reviewed the position and relevancy of open digital badges in learning recognition. 
    In parallel, key gamification theories were introduced and assessed, including \acrshort{sdt}, the \acrshort{mda} framework, flow theory, and \acrshort{fbm}. 
    These foundations directly informed the decisions to structure the platform as a sequential, on-rails experience, emphasising user autonomy, competence, and timely feedback. 
    The use of visual progress indicators, score systems, and locked content emerged from this theoretical grounding, ensuring that gamification elements would serve educational goals rather than superficial engagement.
    \item \textbf{Design Strategy and Comparative Review} A comparative review of existing educational and gamified platforms, such as Duolingo, Khan Academy, Coursera, Mozilla Open Badges and others, revealed consistently applied strategies or game and gamified elements applied within the industry for sustaining engagement, structuring content, and delivering credential-based rewards. 
    These findings directly informed the platformâ€™s mobile-first, one-page layout and task-based structure. 
    The design choices of scroll-snapped sections, touch-friendly layouts, and feedback-rich interactions were deliberately aligned with both usability principles and gamification theory, reinforcing motivation while reducing cognitive friction. 
    Element design emphasised clarity and user intent: colour-coded feedback, progressive content unlocking, and concise and simple typography supported cognitive accessibility.
    The implemented solutions reflect best practices drawn from both theoretical and practical analysis.
    \item \textbf{Platform Development} The educational platform was successfully developed using React.js, Node.js, and OBF API. 
    It integrated gamified components such as a progress bar, point-based scoring, feedback overlays, and badge issuance. 
    Tasks were implemented as interactive modules featuring card sorting, item selection, scenario selection and card association. 
    Technical challenges, such as API limitations with Badgr and badgecraft.eu, were overcome by switching to Open Badge Factory.
    The full experience remained full and functional across devices, reflecting a robust implementation of the design strategy.
    \item \textbf{Testing and Evaluation} The platform was tested with 9 users. 
    Users completed the website experience in full and their task performance and feedback were recorded. 
    Quantitatively, task accuracy ranged from 56\% to 100\%, or up to 88\%, if the task designed as a break is to be excluded. 
    Task 3(scenario selection) was performed the worst, and Task 1(card classification) was performed the best by the users. 
    Task 3 also received the most negative qualitative feedback from the survey. 
    The evaluation confirmed that the platform achieved its learning goals, with strong self-reported user understanding and enjoyment. 
    Despite technical setbacks and a limited sample size, the testing methodology yielded actionable insights, validating both the concept and its execution while identifying concrete paths for improvement in future iterations and research.
\end{enumerate}

\newpage